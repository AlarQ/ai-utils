<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title></title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="ai-utils---complete-ai-toolkit-for-building-ai-agents"><a class="header" href="#ai-utils---complete-ai-toolkit-for-building-ai-agents">AI Utils - Complete AI Toolkit for Building AI Agents</a></h1>
<p>AI Utils is a comprehensive Rust library designed to provide all the essential tools needed to build sophisticated AI agents. It integrates multiple AI services and utilities into a unified, async-first API that makes building AI applications simple and efficient.</p>
<h2 id="-key-features"><a class="header" href="#-key-features">üöÄ Key Features</a></h2>
<ul>
<li><strong>OpenAI Integration</strong>: Complete support for chat completions, embeddings, image generation, and audio transcription</li>
<li><strong>Vector Database</strong>: Seamless integration with Qdrant for vector storage and similarity search</li>
<li><strong>Text Processing</strong>: Advanced text splitting and tokenization with configurable chunking strategies</li>
<li><strong>Monitoring</strong>: Built-in Langfuse integration for comprehensive AI application monitoring</li>
<li><strong>Async-First</strong>: Built on Tokio for high-performance concurrent operations</li>
<li><strong>Type Safety</strong>: Full Rust type safety with comprehensive error handling</li>
</ul>
<h2 id="-architecture"><a class="header" href="#-architecture">üèóÔ∏è Architecture</a></h2>
<pre><code class="language-mermaid">graph TB
    subgraph "AI Utils Core"
        A[Application] --&gt; B[OpenAI Service]
        A --&gt; C[Qdrant Service]
        A --&gt; D[Text Splitter]
        A --&gt; E[Langfuse Service]
        A --&gt; F[Common Utils]
    end
    
    subgraph "External Services"
        B --&gt; G[OpenAI API]
        C --&gt; H[Qdrant Database]
        E --&gt; I[Langfuse Platform]
    end
    
    subgraph "Data Flow"
        J[Input Data] --&gt; D
        D --&gt; K[Chunked Text]
        K --&gt; B
        B --&gt; L[Embeddings]
        L --&gt; C
        C --&gt; M[Vector Search Results]
        M --&gt; A
    end
    
    style A fill:#e1f5fe
    style G fill:#ffebee
    style H fill:#e8f5e8
    style I fill:#fff3e0
</code></pre>
<h2 id="-use-cases"><a class="header" href="#-use-cases">üéØ Use Cases</a></h2>
<ul>
<li><strong>Chat Bots</strong>: Build conversational AI agents with memory and context</li>
<li><strong>Document Q&amp;A</strong>: Create systems that can answer questions from large document collections</li>
<li><strong>Image Analysis</strong>: Process and analyze images with multimodal AI capabilities</li>
<li><strong>Vector Search</strong>: Implement semantic search across text, images, and other data</li>
<li><strong>AI Monitoring</strong>: Track and analyze AI application performance and usage</li>
</ul>
<h2 id="-quick-installation"><a class="header" href="#-quick-installation">üì¶ Quick Installation</a></h2>
<pre><code class="language-bash"># Add to your Cargo.toml
[dependencies]
ai_utils = "0.1.0"
</code></pre>
<h2 id="-environment-setup"><a class="header" href="#-environment-setup">üîß Environment Setup</a></h2>
<pre><code class="language-bash"># Required environment variables
export OPENAI_API_KEY="your-openai-api-key"
export QDRANT_URL="your-qdrant-url"
export QDRANT_API_KEY="your-qdrant-api-key"
export LANGFUSE_PUBLIC_KEY="your-langfuse-public-key"
export LANGFUSE_SECRET_KEY="your-langfuse-secret-key"
</code></pre>
<h2 id="-quick-start"><a class="header" href="#-quick-start">üöÄ Quick Start</a></h2>
<pre><pre class="playground"><code class="language-rust">use ai_utils::{openai::OpenAIService, text_splitter::TextSplitter};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Initialize services
    let openai = OpenAIService::new();
    let splitter = TextSplitter::new(None);
    
    // Process text and get embeddings
    let text = "Your document content here...";
    let chunks = splitter.split(text, 1000)?;
    
    // Generate embeddings
    let embeddings = openai.embed(chunks[0].content.clone()).await?;
    
    println!("Generated {} embeddings", embeddings.len());
    Ok(())
}</code></pre></pre>
<h2 id="-whats-next"><a class="header" href="#-whats-next">üìö What's Next?</a></h2>
<ul>
<li><a href="getting-started/installation.html">Installation Guide</a> - Set up your development environment</li>
<li><a href="getting-started/quick-start.html">Quick Start</a> - Build your first AI agent</li>
<li><a href="core-concepts/architecture.html">Architecture Overview</a> - Understand the system design</li>
<li><a href="examples/">Examples</a> - See real-world usage patterns</li>
</ul>
<h2 id="-contributing"><a class="header" href="#-contributing">ü§ù Contributing</a></h2>
<p>We welcome contributions! See our <a href="contributing/development-setup.html">contributing guide</a> for details on how to get started.</p>
<h2 id="-license"><a class="header" href="#-license">üìÑ License</a></h2>
<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>This guide will help you set up AI Utils in your Rust project.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<ul>
<li>Rust 1.70+ (latest stable recommended)</li>
<li>Cargo package manager</li>
<li>API keys for external services</li>
</ul>
<h2 id="adding-to-your-project"><a class="header" href="#adding-to-your-project">Adding to Your Project</a></h2>
<h3 id="1-add-dependency"><a class="header" href="#1-add-dependency">1. Add Dependency</a></h3>
<p>Add AI Utils to your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
ai_utils = "0.1.0"
tokio = { version = "1.45.1", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
</code></pre>
<h3 id="2-install-mdbook-for-documentation"><a class="header" href="#2-install-mdbook-for-documentation">2. Install mdBook (for documentation)</a></h3>
<pre><code class="language-bash">cargo install mdbook
</code></pre>
<h2 id="environment-configuration"><a class="header" href="#environment-configuration">Environment Configuration</a></h2>
<h3 id="required-environment-variables"><a class="header" href="#required-environment-variables">Required Environment Variables</a></h3>
<p>Create a <code>.env</code> file in your project root:</p>
<pre><code class="language-bash"># OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key

# Qdrant Vector Database
QDRANT_URL=https://your-qdrant-instance.com
QDRANT_API_KEY=your-qdrant-api-key

# Langfuse Monitoring (Optional)
LANGFUSE_PUBLIC_KEY=your-langfuse-public-key
LANGFUSE_SECRET_KEY=your-langfuse-secret-key
</code></pre>
<h3 id="getting-api-keys"><a class="header" href="#getting-api-keys">Getting API Keys</a></h3>
<h4 id="openai-api-key"><a class="header" href="#openai-api-key">OpenAI API Key</a></h4>
<ol>
<li>Visit <a href="https://platform.openai.com/">OpenAI Platform</a></li>
<li>Create an account or sign in</li>
<li>Navigate to API Keys section</li>
<li>Create a new API key</li>
<li>Copy the key to your <code>.env</code> file</li>
</ol>
<h4 id="qdrant-setup"><a class="header" href="#qdrant-setup">Qdrant Setup</a></h4>
<ol>
<li><strong>Cloud Option</strong>: Sign up at <a href="https://cloud.qdrant.io/">Qdrant Cloud</a></li>
<li><strong>Self-hosted</strong>: Follow <a href="https://qdrant.tech/documentation/guides/installation/">Qdrant installation guide</a></li>
<li>Get your API key and endpoint URL</li>
</ol>
<h4 id="langfuse-optional"><a class="header" href="#langfuse-optional">Langfuse (Optional)</a></h4>
<ol>
<li>Visit <a href="https://langfuse.com/">Langfuse</a></li>
<li>Create an account</li>
<li>Get your public and secret keys from the dashboard</li>
</ol>
<h2 id="verification"><a class="header" href="#verification">Verification</a></h2>
<p>Test your installation with a simple example:</p>
<pre><pre class="playground"><code class="language-rust">use ai_utils::openai::OpenAIService;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    dotenv::dotenv().ok();
    
    let openai = OpenAIService::new();
    let embeddings = openai.embed("Hello, world!".to_string()).await?;
    
    println!("Successfully generated {} embeddings", embeddings.len());
    Ok(())
}</code></pre></pre>
<p>Run with:</p>
<pre><code class="language-bash">cargo run
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ul>
<li><a href="getting-started/quick-start.html">Quick Start Guide</a> - Build your first AI agent</li>
<li><a href="getting-started/configuration.html">Configuration</a> - Learn about advanced configuration options</li>
<li><a href="getting-started/../examples/">Examples</a> - See real-world usage patterns</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h1>
<p>Get up and running with AI Utils in minutes. This guide will walk you through building a simple AI agent that can process text and answer questions.</p>
<h2 id="basic-chat-bot"><a class="header" href="#basic-chat-bot">Basic Chat Bot</a></h2>
<p>Let's create a simple chat bot that can maintain conversation context:</p>
<pre><pre class="playground"><code class="language-rust">use ai_utils::{
    openai::{OpenAIService, OpenAIMessage, OpenAIModel},
    text_splitter::TextSplitter,
};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    dotenv::dotenv().ok();
    
    // Initialize services
    let openai = OpenAIService::new();
    let splitter = TextSplitter::new(None);
    
    // System prompt to define the bot's behavior
    let system_message = OpenAIMessage {
        role: "system".to_string(),
        content: "You are a helpful AI assistant. Provide clear, concise answers.".to_string(),
        name: None,
    };
    
    // User message
    let user_message = OpenAIMessage {
        role: "user".to_string(),
        content: "What is the capital of France?".to_string(),
        name: None,
    };
    
    // Create conversation
    let messages = vec![system_message, user_message];
    
    // Get response
    let response = openai.completion(messages, OpenAIModel::GPT35Turbo).await?;
    
    if let Some(choice) = response.choices.first() {
        println!("AI: {}", choice.message.content);
    }
    
    Ok(())
}</code></pre></pre>
<h2 id="document-qa-system"><a class="header" href="#document-qa-system">Document Q&amp;A System</a></h2>
<p>Create a system that can answer questions about documents:</p>
<pre><pre class="playground"><code class="language-rust">use ai_utils::{
    openai::{OpenAIService, OpenAIMessage, OpenAIModel},
    text_splitter::TextSplitter,
    qdrant::QdrantService,
};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    dotenv::dotenv().ok();
    
    let openai = OpenAIService::new();
    let splitter = TextSplitter::new(None);
    let qdrant = QdrantService::new().await?;
    
    // Sample document
    let document = r#"
    Artificial Intelligence (AI) is a branch of computer science that aims to create 
    intelligent machines that work and react like humans. Some of the activities 
    computers with artificial intelligence are designed for include speech recognition, 
    learning, planning, and problem solving.
    "#;
    
    // Split document into chunks
    let chunks = splitter.split(document, 1000)?;
    
    // Create collection for document chunks
    let collection_name = "documents";
    qdrant.create_collection(collection_name, 1536).await?;
    
    // Process each chunk
    for (i, chunk) in chunks.iter().enumerate() {
        // Generate embeddings
        let embeddings = openai.embed(chunk.content.clone()).await?;
        
        // Store in vector database
        qdrant.upsert_points(
            collection_name,
            &amp;[i.to_string()],
            &amp;[embeddings],
            &amp;[chunk.content.clone()],
        ).await?;
    }
    
    // Query the system
    let question = "What is artificial intelligence?";
    let question_embeddings = openai.embed(question.to_string()).await?;
    
    // Search for relevant chunks
    let search_results = qdrant.search_points(
        collection_name,
        &amp;question_embeddings,
        3,
    ).await?;
    
    // Build context from search results
    let context: String = search_results
        .iter()
        .map(|result| result.payload.get("text").unwrap_or(&amp;"".to_string()))
        .collect::&lt;Vec&lt;_&gt;&gt;()
        .join("\n\n");
    
    // Generate answer
    let messages = vec![
        OpenAIMessage {
            role: "system".to_string(),
            content: format!(
                "Answer the question based on the following context:\n\n{}",
                context
            ),
            name: None,
        },
        OpenAIMessage {
            role: "user".to_string(),
            content: question.to_string(),
            name: None,
        },
    ];
    
    let response = openai.completion(messages, OpenAIModel::GPT35Turbo).await?;
    
    if let Some(choice) = response.choices.first() {
        println!("Question: {}", question);
        println!("Answer: {}", choice.message.content);
    }
    
    Ok(())
}</code></pre></pre>
<h2 id="image-analysis"><a class="header" href="#image-analysis">Image Analysis</a></h2>
<p>Process and analyze images with multimodal capabilities:</p>
<pre><pre class="playground"><code class="language-rust">use ai_utils::openai::{OpenAIService, OpenAIMessage, OpenAIImageMessage, OpenAIModel};
use std::fs;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    dotenv::dotenv().ok();
    
    let openai = OpenAIService::new();
    
    // Read image file
    let image_data = fs::read("path/to/your/image.jpg")?;
    let base64_image = base64::encode(&amp;image_data);
    let image_url = format!("data:image/jpeg;base64,{}", base64_image);
    
    // Create image message
    let image_message = OpenAIImageMessage {
        role: "user".to_string(),
        content: vec![image_url],
        name: None,
    };
    
    // Text question about the image
    let text_message = OpenAIMessage {
        role: "user".to_string(),
        content: "What do you see in this image?".to_string(),
        name: None,
    };
    
    // Get multimodal response
    let response = openai.completion_image(
        vec![text_message],
        vec![image_message],
        OpenAIModel::GPT4Vision,
    ).await?;
    
    if let Some(choice) = response.choices.first() {
        println!("Image Analysis: {}", choice.message.content);
    }
    
    Ok(())
}</code></pre></pre>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<h3 id="1-service-initialization"><a class="header" href="#1-service-initialization">1. Service Initialization</a></h3>
<p>All services are initialized with environment variables:</p>
<ul>
<li><code>OpenAIService::new()</code> - Uses <code>OPENAI_API_KEY</code></li>
<li><code>QdrantService::new()</code> - Uses <code>QDRANT_URL</code> and <code>QDRANT_API_KEY</code></li>
</ul>
<h3 id="2-async-operations"><a class="header" href="#2-async-operations">2. Async Operations</a></h3>
<p>All operations are async and should be awaited:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let result = service.operation().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="3-error-handling"><a class="header" href="#3-error-handling">3. Error Handling</a></h3>
<p>Use the <code>?</code> operator for error propagation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let response = openai.completion(messages, model).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<ul>
<li><a href="getting-started/../core-concepts/architecture.html">Architecture Overview</a> - Understand the system design</li>
<li><a href="getting-started/../modules/openai/overview.html">OpenAI Integration</a> - Learn about AI capabilities</li>
<li><a href="getting-started/../modules/qdrant/overview.html">Vector Search</a> - Explore semantic search</li>
<li><a href="getting-started/../examples/">Examples</a> - See more complex use cases</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration"><a class="header" href="#configuration">Configuration</a></h1>
<p>This guide covers all configuration options for AI Utils, including environment variables, service settings, and performance tuning.</p>
<h2 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h2>
<p>AI Utils uses environment variables for configuration. Create a <code>.env</code> file in your project root:</p>
<pre><code class="language-bash"># OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key

# Qdrant Vector Database
QDRANT_URL=https://your-qdrant-instance.com
QDRANT_API_KEY=your-qdrant-api-key

# Langfuse Monitoring (Optional)
LANGFUSE_PUBLIC_KEY=your-langfuse-public-key
LANGFUSE_SECRET_KEY=your-langfuse-secret-key

# Application Settings
RUST_LOG=info
RUST_BACKTRACE=1
</code></pre>
<h2 id="service-configuration"><a class="header" href="#service-configuration">Service Configuration</a></h2>
<h3 id="openai-service"><a class="header" href="#openai-service">OpenAI Service</a></h3>
<p>The OpenAI service is configured automatically from environment variables:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::openai::OpenAIService;

// Automatically reads OPENAI_API_KEY from environment
let openai = OpenAIService::new();
<span class="boring">}</span></code></pre></pre>
<p><strong>Available Models:</strong></p>
<ul>
<li><code>GPT35Turbo</code> - Fast, cost-effective</li>
<li><code>GPT4</code> - More capable, better reasoning</li>
<li><code>GPT4Vision</code> - Multimodal (text + image)</li>
</ul>
<h3 id="qdrant-service"><a class="header" href="#qdrant-service">Qdrant Service</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::qdrant::QdrantService;

// Automatically reads QDRANT_URL and QDRANT_API_KEY
let qdrant = QdrantService::new().await?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Configuration Options:</strong></p>
<ul>
<li><code>QDRANT_URL</code> - Server endpoint</li>
<li><code>QDRANT_API_KEY</code> - Authentication key</li>
<li>Connection timeout (configurable)</li>
<li>Retry policies</li>
</ul>
<h3 id="text-splitter"><a class="header" href="#text-splitter">Text Splitter</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::text_splitter::TextSplitter;

// Default configuration
let splitter = TextSplitter::new(None);

// Custom configuration
let config = TextSplitterConfig {
    chunk_size: 1000,
    chunk_overlap: 200,
    separator: "\n\n".to_string(),
};
let splitter = TextSplitter::new(Some(config));
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-configuration"><a class="header" href="#performance-configuration">Performance Configuration</a></h2>
<h3 id="connection-pooling"><a class="header" href="#connection-pooling">Connection Pooling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Configure HTTP client for better performance
use reqwest::Client;

let client = Client::builder()
    .pool_max_idle_per_host(10)
    .timeout(std::time::Duration::from_secs(30))
    .build()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-processing"><a class="header" href="#batch-processing">Batch Processing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Configure batch sizes for optimal performance
const BATCH_SIZE: usize = 100; // Embeddings
const VECTOR_BATCH_SIZE: usize = 1000; // Vector operations
<span class="boring">}</span></code></pre></pre>
<h3 id="caching"><a class="header" href="#caching">Caching</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::collections::HashMap;
use std::sync::Mutex;

struct Cache {
    embeddings: Mutex&lt;HashMap&lt;String, Vec&lt;f32&gt;&gt;&gt;,
    responses: Mutex&lt;HashMap&lt;String, String&gt;&gt;,
}

impl Cache {
    pub fn new() -&gt; Self {
        Self {
            embeddings: Mutex::new(HashMap::new()),
            responses: Mutex::new(HashMap::new()),
        }
    }
    
    pub fn get_embedding(&amp;self, text: &amp;str) -&gt; Option&lt;Vec&lt;f32&gt;&gt; {
        self.embeddings.lock().unwrap().get(text).cloned()
    }
    
    pub fn set_embedding(&amp;self, text: String, embedding: Vec&lt;f32&gt;) {
        self.embeddings.lock().unwrap().insert(text, embedding);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="logging-configuration"><a class="header" href="#logging-configuration">Logging Configuration</a></h2>
<h3 id="basic-logging"><a class="header" href="#basic-logging">Basic Logging</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing_subscriber;

// Initialize logging
tracing_subscriber::fmt::init();

// Set log level via environment
// RUST_LOG=debug cargo run
<span class="boring">}</span></code></pre></pre>
<h3 id="structured-logging"><a class="header" href="#structured-logging">Structured Logging</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing::{info, warn, error, instrument};

#[instrument]
async fn process_document(content: &amp;str) -&gt; Result&lt;(), Error&gt; {
    info!(length = content.len(), "Processing document");
    
    // Process document...
    
    info!("Document processed successfully");
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-configuration"><a class="header" href="#error-handling-configuration">Error Handling Configuration</a></h2>
<h3 id="custom-error-types"><a class="header" href="#custom-error-types">Custom Error Types</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use thiserror::Error;

#[derive(Error, Debug)]
pub enum AppError {
    #[error("OpenAI API error: {0}")]
    OpenAI(#[from] ai_utils::error::Error),
    
    #[error("Configuration error: {0}")]
    Config(String),
    
    #[error("Rate limit exceeded")]
    RateLimit,
}

// Use in your application
async fn process_with_retry() -&gt; Result&lt;(), AppError&gt; {
    // Implementation with retry logic
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="retry-configuration"><a class="header" href="#retry-configuration">Retry Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::time::{sleep, Duration};

async fn with_retry&lt;F, T, E&gt;(mut f: F, max_retries: usize) -&gt; Result&lt;T, E&gt;
where
    F: FnMut() -&gt; Result&lt;T, E&gt;,
    E: std::fmt::Debug,
{
    let mut attempts = 0;
    loop {
        match f() {
            Ok(result) =&gt; return Ok(result),
            Err(e) =&gt; {
                attempts += 1;
                if attempts &gt;= max_retries {
                    return Err(e);
                }
                
                let delay = Duration::from_secs(2_u64.pow(attempts as u32));
                sleep(delay).await;
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="security-configuration"><a class="header" href="#security-configuration">Security Configuration</a></h2>
<h3 id="api-key-management"><a class="header" href="#api-key-management">API Key Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use environment variables (recommended)
let api_key = std::env::var("OPENAI_API_KEY")
    .expect("OPENAI_API_KEY must be set");

// Or use a secure key management service
let api_key = get_secret_from_vault("openai-api-key").await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="input-validation"><a class="header" href="#input-validation">Input Validation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use regex::Regex;

fn validate_input(input: &amp;str) -&gt; Result&lt;(), Error&gt; {
    // Check for malicious content
    let malicious_pattern = Regex::new(r"&lt;script|javascript:|data:text/html").unwrap();
    
    if malicious_pattern.is_match(input) {
        return Err(Error::InvalidInput("Potentially malicious input detected".into()));
    }
    
    // Check length limits
    if input.len() &gt; 10000 {
        return Err(Error::InvalidInput("Input too long".into()));
    }
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="development-vs-production"><a class="header" href="#development-vs-production">Development vs Production</a></h2>
<h3 id="development-configuration"><a class="header" href="#development-configuration">Development Configuration</a></h3>
<pre><code class="language-bash"># .env.development
RUST_LOG=debug
RUST_BACKTRACE=1
OPENAI_API_KEY=sk-test-...
QDRANT_URL=http://localhost:6333
</code></pre>
<h3 id="production-configuration"><a class="header" href="#production-configuration">Production Configuration</a></h3>
<pre><code class="language-bash"># .env.production
RUST_LOG=warn
OPENAI_API_KEY=sk-prod-...
QDRANT_URL=https://production-qdrant.com
LANGFUSE_PUBLIC_KEY=prod-key
LANGFUSE_SECRET_KEY=prod-secret
</code></pre>
<h3 id="configuration-loading"><a class="header" href="#configuration-loading">Configuration Loading</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use dotenv::dotenv;

fn load_config() {
    // Load environment-specific config
    let env = std::env::var("RUST_ENV").unwrap_or_else(|_| "development".to_string());
    
    match env.as_str() {
        "production" =&gt; dotenv::from_filename(".env.production").ok(),
        "staging" =&gt; dotenv::from_filename(".env.staging").ok(),
        _ =&gt; dotenv::from_filename(".env.development").ok(),
    };
}
<span class="boring">}</span></code></pre></pre>
<h2 id="monitoring-configuration"><a class="header" href="#monitoring-configuration">Monitoring Configuration</a></h2>
<h3 id="langfuse-integration"><a class="header" href="#langfuse-integration">Langfuse Integration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::langfuse::LangfuseService;

let langfuse = LangfuseService::new().await?;

// Track operations
langfuse.trace("document-processing", |trace| {
    trace.span("embedding-generation", |span| {
        // Generate embeddings
        span.end();
    });
    trace.end();
}).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="metrics-collection"><a class="header" href="#metrics-collection">Metrics Collection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::atomic::{AtomicU64, Ordering};

#[derive(Default)]
struct Metrics {
    requests: AtomicU64,
    errors: AtomicU64,
    latency: AtomicU64,
}

impl Metrics {
    pub fn increment_requests(&amp;self) {
        self.requests.fetch_add(1, Ordering::Relaxed);
    }
    
    pub fn record_latency(&amp;self, duration: Duration) {
        self.latency.store(duration.as_millis() as u64, Ordering::Relaxed);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="1-environment-management"><a class="header" href="#1-environment-management">1. Environment Management</a></h3>
<ul>
<li>Never commit API keys to version control</li>
<li>Use different keys for development and production</li>
<li>Rotate keys regularly</li>
</ul>
<h3 id="2-performance-tuning"><a class="header" href="#2-performance-tuning">2. Performance Tuning</a></h3>
<ul>
<li>Monitor API usage and costs</li>
<li>Implement appropriate caching strategies</li>
<li>Use batch operations when possible</li>
</ul>
<h3 id="3-error-handling-1"><a class="header" href="#3-error-handling-1">3. Error Handling</a></h3>
<ul>
<li>Implement comprehensive error handling</li>
<li>Use structured logging for debugging</li>
<li>Set up monitoring and alerting</li>
</ul>
<h3 id="4-security"><a class="header" href="#4-security">4. Security</a></h3>
<ul>
<li>Validate all inputs</li>
<li>Use HTTPS for all external communications</li>
<li>Implement rate limiting</li>
</ul>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<ul>
<li><a href="getting-started/../deployment/production-setup.html">Production Setup</a> - Deploy to production</li>
<li><a href="getting-started/../deployment/performance-tuning.html">Performance Tuning</a> - Optimize performance</li>
<li><a href="getting-started/../deployment/environment-variables.html">Environment Variables</a> - Advanced environment configuration</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h1>
<p>AI Utils is designed with a modular, service-oriented architecture that provides a clean separation of concerns while maintaining high performance and flexibility.</p>
<h2 id="system-architecture"><a class="header" href="#system-architecture">System Architecture</a></h2>
<pre><code class="language-mermaid">graph TB
    subgraph "Application Layer"
        A[Your Application] --&gt; B[AI Utils Core]
    end
    
    subgraph "Service Layer"
        B --&gt; C[OpenAI Service]
        B --&gt; D[Qdrant Service]
        B --&gt; E[Text Splitter]
        B --&gt; F[Langfuse Service]
        B --&gt; G[Common Utils]
    end
    
    subgraph "External APIs"
        C --&gt; H[OpenAI API]
        D --&gt; I[Qdrant Database]
        F --&gt; J[Langfuse Platform]
    end
    
    subgraph "Data Flow"
        K[Input Data] --&gt; E
        E --&gt; L[Chunked Text]
        L --&gt; C
        C --&gt; M[Embeddings/Completions]
        M --&gt; D
        D --&gt; N[Vector Search Results]
        N --&gt; A
    end
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style H fill:#ffebee
    style I fill:#e8f5e8
    style J fill:#fff3e0
</code></pre>
<h2 id="core-components"><a class="header" href="#core-components">Core Components</a></h2>
<h3 id="1-service-layer"><a class="header" href="#1-service-layer">1. Service Layer</a></h3>
<p>The service layer provides the main interfaces for interacting with external APIs and services:</p>
<h4 id="openai-service-1"><a class="header" href="#openai-service-1">OpenAI Service</a></h4>
<ul>
<li><strong>Purpose</strong>: Handles all OpenAI API interactions</li>
<li><strong>Capabilities</strong>: Chat completions, embeddings, image generation, audio transcription</li>
<li><strong>Key Features</strong>:
<ul>
<li>Async operations with proper error handling</li>
<li>Support for multiple models (GPT-3.5, GPT-4, GPT-4 Vision)</li>
<li>Multimodal capabilities (text + image)</li>
</ul>
</li>
</ul>
<h4 id="qdrant-service-1"><a class="header" href="#qdrant-service-1">Qdrant Service</a></h4>
<ul>
<li><strong>Purpose</strong>: Vector database operations for semantic search</li>
<li><strong>Capabilities</strong>: Collection management, vector storage, similarity search</li>
<li><strong>Key Features</strong>:
<ul>
<li>High-performance vector operations</li>
<li>Metadata storage with vectors</li>
<li>Configurable search parameters</li>
</ul>
</li>
</ul>
<h4 id="text-splitter-1"><a class="header" href="#text-splitter-1">Text Splitter</a></h4>
<ul>
<li><strong>Purpose</strong>: Intelligent text chunking for processing large documents</li>
<li><strong>Capabilities</strong>: Token-aware splitting, overlap management, metadata preservation</li>
<li><strong>Key Features</strong>:
<ul>
<li>Configurable chunk sizes</li>
<li>Semantic boundary detection</li>
<li>Token counting with tiktoken</li>
</ul>
</li>
</ul>
<h4 id="langfuse-service"><a class="header" href="#langfuse-service">Langfuse Service</a></h4>
<ul>
<li><strong>Purpose</strong>: AI application monitoring and observability</li>
<li><strong>Capabilities</strong>: Trace tracking, span management, performance monitoring</li>
<li><strong>Key Features</strong>:
<ul>
<li>Request/response logging</li>
<li>Performance metrics</li>
<li>Error tracking</li>
</ul>
</li>
</ul>
<h3 id="2-common-utilities"><a class="header" href="#2-common-utilities">2. Common Utilities</a></h3>
<p>Shared utilities and types used across all services:</p>
<ul>
<li><strong>Error Handling</strong>: Centralized error types and handling</li>
<li><strong>Base64 Encoding</strong>: Image and binary data processing</li>
<li><strong>Image Processing</strong>: Image manipulation and format conversion</li>
<li><strong>Common Types</strong>: Shared data structures and enums</li>
</ul>
<h2 id="data-flow-patterns"><a class="header" href="#data-flow-patterns">Data Flow Patterns</a></h2>
<h3 id="1-document-processing-pipeline"><a class="header" href="#1-document-processing-pipeline">1. Document Processing Pipeline</a></h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant App as Application
    participant TS as Text Splitter
    participant OAI as OpenAI Service
    participant QD as Qdrant Service
    
    App-&gt;&gt;TS: Split document
    TS-&gt;&gt;TS: Tokenize and chunk
    TS-&gt;&gt;App: Return chunks
    
    loop For each chunk
        App-&gt;&gt;OAI: Generate embeddings
        OAI-&gt;&gt;App: Return embeddings
        App-&gt;&gt;QD: Store vectors
        QD-&gt;&gt;App: Confirm storage
    end
</code></pre>
<h3 id="2-query-processing-pipeline"><a class="header" href="#2-query-processing-pipeline">2. Query Processing Pipeline</a></h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant User as User
    participant App as Application
    participant OAI as OpenAI Service
    participant QD as Qdrant Service
    
    User-&gt;&gt;App: Ask question
    App-&gt;&gt;OAI: Generate query embeddings
    OAI-&gt;&gt;App: Return embeddings
    App-&gt;&gt;QD: Search similar vectors
    QD-&gt;&gt;App: Return relevant chunks
    App-&gt;&gt;OAI: Generate answer with context
    OAI-&gt;&gt;App: Return answer
    App-&gt;&gt;User: Provide response
</code></pre>
<h3 id="3-multimodal-processing"><a class="header" href="#3-multimodal-processing">3. Multimodal Processing</a></h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant App as Application
    participant OAI as OpenAI Service
    
    App-&gt;&gt;App: Load image
    App-&gt;&gt;App: Encode to base64
    App-&gt;&gt;OAI: Send text + image
    OAI-&gt;&gt;OAI: Process multimodal input
    OAI-&gt;&gt;App: Return analysis
</code></pre>
<h2 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h2>
<h3 id="1-async-first-design"><a class="header" href="#1-async-first-design">1. Async-First Design</a></h3>
<ul>
<li>All operations are asynchronous using Tokio</li>
<li>Non-blocking I/O for high performance</li>
<li>Proper resource management</li>
</ul>
<h3 id="2-error-handling"><a class="header" href="#2-error-handling">2. Error Handling</a></h3>
<ul>
<li>Comprehensive error types with <code>thiserror</code></li>
<li>Graceful degradation</li>
<li>Detailed error context</li>
</ul>
<h3 id="3-type-safety"><a class="header" href="#3-type-safety">3. Type Safety</a></h3>
<ul>
<li>Strong typing throughout the codebase</li>
<li>Rust's ownership system for memory safety</li>
<li>Compile-time guarantees</li>
</ul>
<h3 id="4-modularity"><a class="header" href="#4-modularity">4. Modularity</a></h3>
<ul>
<li>Clear separation between services</li>
<li>Minimal coupling between components</li>
<li>Easy to extend and customize</li>
</ul>
<h3 id="5-configuration"><a class="header" href="#5-configuration">5. Configuration</a></h3>
<ul>
<li>Environment-based configuration</li>
<li>Sensible defaults</li>
<li>Easy to override for different environments</li>
</ul>
<h2 id="performance-considerations"><a class="header" href="#performance-considerations">Performance Considerations</a></h2>
<h3 id="1-connection-pooling"><a class="header" href="#1-connection-pooling">1. Connection Pooling</a></h3>
<ul>
<li>Reuse HTTP connections where possible</li>
<li>Efficient resource utilization</li>
<li>Reduced latency</li>
</ul>
<h3 id="2-batch-operations"><a class="header" href="#2-batch-operations">2. Batch Operations</a></h3>
<ul>
<li>Support for batch processing where available</li>
<li>Reduced API calls</li>
<li>Better throughput</li>
</ul>
<h3 id="3-caching"><a class="header" href="#3-caching">3. Caching</a></h3>
<ul>
<li>Embedding caching for repeated text</li>
<li>Vector search result caching</li>
<li>Configurable cache strategies</li>
</ul>
<h2 id="security"><a class="header" href="#security">Security</a></h2>
<h3 id="1-api-key-management"><a class="header" href="#1-api-key-management">1. API Key Management</a></h3>
<ul>
<li>Environment variable configuration</li>
<li>No hardcoded secrets</li>
<li>Secure key rotation support</li>
</ul>
<h3 id="2-data-privacy"><a class="header" href="#2-data-privacy">2. Data Privacy</a></h3>
<ul>
<li>Local processing where possible</li>
<li>Minimal data transmission</li>
<li>Configurable data retention</li>
</ul>
<h3 id="3-input-validation"><a class="header" href="#3-input-validation">3. Input Validation</a></h3>
<ul>
<li>Comprehensive input sanitization</li>
<li>Rate limiting support</li>
<li>Malicious input protection</li>
</ul>
<h2 id="extensibility"><a class="header" href="#extensibility">Extensibility</a></h2>
<p>The architecture is designed to be easily extensible:</p>
<ul>
<li><strong>New Services</strong>: Add new service modules following the existing patterns</li>
<li><strong>Custom Models</strong>: Support for different AI models and providers</li>
<li><strong>Storage Backends</strong>: Pluggable vector database implementations</li>
<li><strong>Monitoring</strong>: Extensible monitoring and logging</li>
</ul>
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<ul>
<li><a href="core-concepts/async-operations.html">Async Operations</a> - Learn about async patterns</li>
<li><a href="core-concepts/error-handling.html">Error Handling</a> - Understand error management</li>
<li><a href="core-concepts/../modules/openai/overview.html">OpenAI Integration</a> - Deep dive into AI capabilities</li>
<li><a href="core-concepts/../modules/qdrant/overview.html">Vector Search</a> - Explore semantic search</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="async-operations"><a class="header" href="#async-operations">Async Operations</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="openai-integration"><a class="header" href="#openai-integration">OpenAI Integration</a></h1>
<p>The OpenAI module provides comprehensive integration with OpenAI's API, supporting chat completions, embeddings, image generation, and audio transcription.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<pre><code class="language-mermaid">graph LR
    subgraph "OpenAI Service"
        A[OpenAIService] --&gt; B[Chat Completions]
        A --&gt; C[Embeddings]
        A --&gt; D[Image Generation]
        A --&gt; E[Audio Transcription]
    end
    
    subgraph "Models"
        B --&gt; F[GPT-3.5 Turbo]
        B --&gt; G[GPT-4]
        B --&gt; H[GPT-4 Vision]
        C --&gt; I[text-embedding-ada-002]
        D --&gt; J[DALL-E 3]
        E --&gt; K[Whisper]
    end
    
    style A fill:#e3f2fd
    style F fill:#ffebee
    style G fill:#ffebee
    style H fill:#ffebee
</code></pre>
<h2 id="key-features"><a class="header" href="#key-features">Key Features</a></h2>
<ul>
<li><strong>Chat Completions</strong>: Multi-turn conversations with context management</li>
<li><strong>Embeddings</strong>: High-quality vector representations for semantic search</li>
<li><strong>Image Generation</strong>: Create images from text descriptions</li>
<li><strong>Audio Transcription</strong>: Convert speech to text</li>
<li><strong>Multimodal Support</strong>: Process text and images together</li>
<li><strong>Async Operations</strong>: Non-blocking API calls with proper error handling</li>
</ul>
<h2 id="service-initialization"><a class="header" href="#service-initialization">Service Initialization</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::openai::OpenAIService;

// Initialize with environment variable
let openai = OpenAIService::new();
<span class="boring">}</span></code></pre></pre>
<p>The service automatically reads the <code>OPENAI_API_KEY</code> environment variable.</p>
<h2 id="available-models"><a class="header" href="#available-models">Available Models</a></h2>
<h3 id="chat-models"><a class="header" href="#chat-models">Chat Models</a></h3>
<ul>
<li><code>GPT35Turbo</code> - Fast, cost-effective for most tasks</li>
<li><code>GPT4</code> - More capable, better reasoning</li>
<li><code>GPT4Vision</code> - Multimodal (text + image)</li>
</ul>
<h3 id="embedding-models"><a class="header" href="#embedding-models">Embedding Models</a></h3>
<ul>
<li><code>TextEmbeddingAda002</code> - High-quality embeddings (1536 dimensions)</li>
</ul>
<h3 id="image-generation"><a class="header" href="#image-generation">Image Generation</a></h3>
<ul>
<li><code>DallE3</code> - High-quality image generation</li>
</ul>
<h3 id="audio-models"><a class="header" href="#audio-models">Audio Models</a></h3>
<ul>
<li><code>Whisper</code> - Speech-to-text transcription</li>
</ul>
<h2 id="usage-patterns"><a class="header" href="#usage-patterns">Usage Patterns</a></h2>
<h3 id="1-basic-chat-completion"><a class="header" href="#1-basic-chat-completion">1. Basic Chat Completion</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::openai::{OpenAIService, OpenAIMessage, OpenAIModel};

let openai = OpenAIService::new();

let messages = vec![
    OpenAIMessage {
        role: "system".to_string(),
        content: "You are a helpful assistant.".to_string(),
        name: None,
    },
    OpenAIMessage {
        role: "user".to_string(),
        content: "What is the weather like?".to_string(),
        name: None,
    },
];

let response = openai.completion(messages, OpenAIModel::GPT35Turbo).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="2-embedding-generation"><a class="header" href="#2-embedding-generation">2. Embedding Generation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let text = "This is a sample text for embedding.";
let embeddings = openai.embed(text.to_string()).await?;
println!("Generated {} embeddings", embeddings.len());
<span class="boring">}</span></code></pre></pre>
<h3 id="3-image-generation"><a class="header" href="#3-image-generation">3. Image Generation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let prompt = "A beautiful sunset over mountains";
let image_url = openai.generate_image_url(prompt.to_string()).await?;
println!("Generated image: {}", image_url);
<span class="boring">}</span></code></pre></pre>
<h3 id="4-audio-transcription"><a class="header" href="#4-audio-transcription">4. Audio Transcription</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let audio_data = std::fs::read("audio.mp3")?;
let transcript = openai.transcribe(audio_data).await?;
println!("Transcript: {}", transcript);
<span class="boring">}</span></code></pre></pre>
<h3 id="5-multimodal-analysis"><a class="header" href="#5-multimodal-analysis">5. Multimodal Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::openai::{OpenAIMessage, OpenAIImageMessage};

let text_message = OpenAIMessage {
    role: "user".to_string(),
    content: "What do you see in this image?".to_string(),
    name: None,
};

let image_message = OpenAIImageMessage {
    role: "user".to_string(),
    content: vec![base64_image_url],
    name: None,
};

let response = openai.completion_image(
    vec![text_message],
    vec![image_message],
    OpenAIModel::GPT4Vision,
).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="message-types"><a class="header" href="#message-types">Message Types</a></h2>
<h3 id="openaimessage"><a class="header" href="#openaimessage">OpenAIMessage</a></h3>
<p>Standard text messages for chat completions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct OpenAIMessage {
    pub role: String,      // "system", "user", "assistant"
    pub content: String,   // Message content
    pub name: Option&lt;String&gt;, // Optional name for the message
}
<span class="boring">}</span></code></pre></pre>
<h3 id="openaiimagemessage"><a class="header" href="#openaiimagemessage">OpenAIImageMessage</a></h3>
<p>Messages containing images for multimodal processing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct OpenAIImageMessage {
    pub role: String,           // "user"
    pub content: Vec&lt;String&gt;,   // Base64 encoded image URLs
    pub name: Option&lt;String&gt;,   // Optional name
}
<span class="boring">}</span></code></pre></pre>
<h2 id="response-types"><a class="header" href="#response-types">Response Types</a></h2>
<h3 id="chatcompletion"><a class="header" href="#chatcompletion">ChatCompletion</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ChatCompletion {
    pub choices: Vec&lt;Choice&gt;,
    pub model: String,
    pub usage: Option&lt;Usage&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="usage-information"><a class="header" href="#usage-information">Usage Information</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Usage {
    pub prompt_tokens: u32,
    pub completion_tokens: u32,
    pub total_tokens: u32,
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h2>
<p>The OpenAI service uses comprehensive error handling:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match openai.completion(messages, model).await {
    Ok(response) =&gt; {
        // Handle successful response
    },
    Err(Error::OpenAI(api_error)) =&gt; {
        // Handle OpenAI API errors
    },
    Err(Error::Network(network_error)) =&gt; {
        // Handle network errors
    },
    Err(e) =&gt; {
        // Handle other errors
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="1-model-selection"><a class="header" href="#1-model-selection">1. Model Selection</a></h3>
<ul>
<li>Use <code>GPT35Turbo</code> for most conversational tasks</li>
<li>Use <code>GPT4</code> for complex reasoning or analysis</li>
<li>Use <code>GPT4Vision</code> for image analysis</li>
</ul>
<h3 id="2-message-management"><a class="header" href="#2-message-management">2. Message Management</a></h3>
<ul>
<li>Keep conversation context manageable</li>
<li>Use system messages to define behavior</li>
<li>Clear user messages for better responses</li>
</ul>
<h3 id="3-error-handling-2"><a class="header" href="#3-error-handling-2">3. Error Handling</a></h3>
<ul>
<li>Always handle API errors gracefully</li>
<li>Implement retry logic for transient failures</li>
<li>Log errors for debugging</li>
</ul>
<h3 id="4-rate-limiting"><a class="header" href="#4-rate-limiting">4. Rate Limiting</a></h3>
<ul>
<li>Respect OpenAI's rate limits</li>
<li>Implement backoff strategies</li>
<li>Monitor usage and costs</li>
</ul>
<h2 id="performance-considerations-1"><a class="header" href="#performance-considerations-1">Performance Considerations</a></h2>
<h3 id="1-batch-processing"><a class="header" href="#1-batch-processing">1. Batch Processing</a></h3>
<ul>
<li>Group related requests when possible</li>
<li>Use concurrent requests for independent operations</li>
<li>Cache embeddings for repeated text</li>
</ul>
<h3 id="2-token-management"><a class="header" href="#2-token-management">2. Token Management</a></h3>
<ul>
<li>Monitor token usage to control costs</li>
<li>Use appropriate chunk sizes for embeddings</li>
<li>Implement token counting for large documents</li>
</ul>
<h3 id="3-caching-1"><a class="header" href="#3-caching-1">3. Caching</a></h3>
<ul>
<li>Cache embeddings for repeated content</li>
<li>Store conversation history efficiently</li>
<li>Implement result caching where appropriate</li>
</ul>
<h2 id="next-steps-4"><a class="header" href="#next-steps-4">Next Steps</a></h2>
<ul>
<li><a href="modules/openai/chat-completions.html">Chat Completions</a> - Deep dive into conversation handling</li>
<li><a href="modules/openai/embeddings.html">Embeddings</a> - Learn about vector representations</li>
<li><a href="modules/openai/image-generation.html">Image Generation</a> - Create images from text</li>
<li><a href="modules/openai/audio-transcription.html">Audio Transcription</a> - Convert speech to text</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chat-completions"><a class="header" href="#chat-completions">Chat Completions</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="embeddings"><a class="header" href="#embeddings">Embeddings</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="image-generation-1"><a class="header" href="#image-generation-1">Image Generation</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="audio-transcription"><a class="header" href="#audio-transcription">Audio Transcription</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="qdrant-vector-database"><a class="header" href="#qdrant-vector-database">Qdrant Vector Database</a></h1>
<p>The Qdrant module provides seamless integration with Qdrant vector database for high-performance vector storage and similarity search operations.</p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<pre><code class="language-mermaid">graph TB
    subgraph "Qdrant Service"
        A[QdrantService] --&gt; B[Collection Management]
        A --&gt; C[Vector Operations]
        A --&gt; D[Search Operations]
        A --&gt; E[Metadata Management]
    end
    
    subgraph "Operations"
        B --&gt; F[Create Collection]
        B --&gt; G[Delete Collection]
        B --&gt; H[List Collections]
        C --&gt; I[Upsert Points]
        C --&gt; J[Delete Points]
        D --&gt; K[Search Points]
        D --&gt; L[Recommend Points]
        E --&gt; M[Update Payload]
    end
    
    subgraph "Data Flow"
        N[Embeddings] --&gt; I
        I --&gt; O[Vector Storage]
        O --&gt; K
        K --&gt; P[Search Results]
    end
    
    style A fill:#e8f5e8
    style O fill:#f3e5f5
    style P fill:#fff3e0
</code></pre>
<h2 id="key-features-1"><a class="header" href="#key-features-1">Key Features</a></h2>
<ul>
<li><strong>High-Performance Vector Storage</strong>: Optimized for large-scale vector operations</li>
<li><strong>Similarity Search</strong>: Fast semantic search with configurable distance metrics</li>
<li><strong>Metadata Storage</strong>: Store rich metadata alongside vectors</li>
<li><strong>Collection Management</strong>: Create, configure, and manage vector collections</li>
<li><strong>Batch Operations</strong>: Efficient bulk operations for large datasets</li>
<li><strong>Async Operations</strong>: Non-blocking operations with proper error handling</li>
</ul>
<h2 id="service-initialization-1"><a class="header" href="#service-initialization-1">Service Initialization</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::qdrant::QdrantService;

// Initialize with environment variables
let qdrant = QdrantService::new().await?;
<span class="boring">}</span></code></pre></pre>
<p>The service automatically reads:</p>
<ul>
<li><code>QDRANT_URL</code> - Qdrant server endpoint</li>
<li><code>QDRANT_API_KEY</code> - API key for authentication</li>
</ul>
<h2 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h2>
<h3 id="collections"><a class="header" href="#collections">Collections</a></h3>
<p>Collections are the primary organizational unit in Qdrant:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create a collection for document embeddings
qdrant.create_collection("documents", 1536).await?;

// List all collections
let collections = qdrant.list_collections().await?;

// Delete a collection
qdrant.delete_collection("documents").await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="points"><a class="header" href="#points">Points</a></h3>
<p>Points represent individual vectors with metadata:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Point structure
struct Point {
    id: String,           // Unique identifier
    vector: Vec&lt;f32&gt;,     // Vector representation
    payload: HashMap&lt;String, String&gt;, // Metadata
}
<span class="boring">}</span></code></pre></pre>
<h3 id="payload"><a class="header" href="#payload">Payload</a></h3>
<p>Payload contains metadata associated with vectors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let payload = HashMap::from([
    ("text".to_string(), "Document content".to_string()),
    ("source".to_string(), "file.pdf".to_string()),
    ("timestamp".to_string(), "2024-01-01".to_string()),
]);
<span class="boring">}</span></code></pre></pre>
<h2 id="usage-patterns-1"><a class="header" href="#usage-patterns-1">Usage Patterns</a></h2>
<h3 id="1-basic-vector-storage"><a class="header" href="#1-basic-vector-storage">1. Basic Vector Storage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::qdrant::QdrantService;

let qdrant = QdrantService::new().await?;

// Create collection for embeddings (1536 dimensions)
qdrant.create_collection("embeddings", 1536).await?;

// Store vectors with metadata
let ids = vec!["doc1".to_string(), "doc2".to_string()];
let vectors = vec![
    vec![0.1, 0.2, 0.3, /* ... */], // 1536 dimensions
    vec![0.4, 0.5, 0.6, /* ... */],
];
let payloads = vec![
    HashMap::from([("text".to_string(), "First document".to_string())]),
    HashMap::from([("text".to_string(), "Second document".to_string())]),
];

qdrant.upsert_points("embeddings", &amp;ids, &amp;vectors, &amp;payloads).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="2-similarity-search"><a class="header" href="#2-similarity-search">2. Similarity Search</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Search for similar vectors
let query_vector = vec![0.1, 0.2, 0.3, /* ... */]; // 1536 dimensions
let results = qdrant.search_points(
    "embeddings",
    &amp;query_vector,
    5, // Top 5 results
).await?;

for result in results {
    println!("Score: {}, Text: {}", 
        result.score, 
        result.payload.get("text").unwrap_or(&amp;"".to_string())
    );
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-document-qa-system"><a class="header" href="#3-document-qa-system">3. Document Q&amp;A System</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::{openai::OpenAIService, qdrant::QdrantService};

let openai = OpenAIService::new();
let qdrant = QdrantService::new().await?;

// Store document chunks
async fn store_document_chunks(
    qdrant: &amp;QdrantService,
    chunks: Vec&lt;DocumentChunk&gt;,
) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    for (i, chunk) in chunks.iter().enumerate() {
        let embeddings = openai.embed(chunk.content.clone()).await?;
        
        qdrant.upsert_points(
            "documents",
            &amp;[i.to_string()],
            &amp;[embeddings],
            &amp;[HashMap::from([("text".to_string(), chunk.content.clone())])],
        ).await?;
    }
    Ok(())
}

// Query documents
async fn query_documents(
    qdrant: &amp;QdrantService,
    question: &amp;str,
) -&gt; Result&lt;Vec&lt;String&gt;, Box&lt;dyn std::error::Error&gt;&gt; {
    let question_embeddings = openai.embed(question.to_string()).await?;
    
    let results = qdrant.search_points(
        "documents",
        &amp;question_embeddings,
        3,
    ).await?;
    
    let relevant_texts: Vec&lt;String&gt; = results
        .iter()
        .map(|r| r.payload.get("text").unwrap_or(&amp;"".to_string()).clone())
        .collect();
    
    Ok(relevant_texts)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="4-batch-operations"><a class="header" href="#4-batch-operations">4. Batch Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Process large datasets efficiently
async fn batch_upsert(
    qdrant: &amp;QdrantService,
    collection: &amp;str,
    data: Vec&lt;(String, Vec&lt;f32&gt;, HashMap&lt;String, String&gt;)&gt;,
    batch_size: usize,
) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    for chunk in data.chunks(batch_size) {
        let ids: Vec&lt;String&gt; = chunk.iter().map(|(id, _, _)| id.clone()).collect();
        let vectors: Vec&lt;Vec&lt;f32&gt;&gt; = chunk.iter().map(|(_, vec, _)| vec.clone()).collect();
        let payloads: Vec&lt;HashMap&lt;String, String&gt;&gt; = chunk.iter().map(|(_, _, payload)| payload.clone()).collect();
        
        qdrant.upsert_points(collection, &amp;ids, &amp;vectors, &amp;payloads).await?;
    }
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="search-configuration"><a class="header" href="#search-configuration">Search Configuration</a></h2>
<h3 id="distance-metrics"><a class="header" href="#distance-metrics">Distance Metrics</a></h3>
<p>Qdrant supports multiple distance metrics:</p>
<ul>
<li><strong>Cosine</strong>: Normalized vectors, angle-based similarity</li>
<li><strong>Euclidean</strong>: Straight-line distance between vectors</li>
<li><strong>Dot Product</strong>: Raw similarity score</li>
</ul>
<h3 id="search-parameters"><a class="header" href="#search-parameters">Search Parameters</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Advanced search with filters
let search_params = SearchParams {
    limit: 10,
    offset: 0,
    with_payload: true,
    with_vector: false,
    score_threshold: Some(0.8),
    filter: Some(Filter {
        must: vec![
            Condition::Field(FieldCondition {
                key: "category".to_string(),
                r#match: Match::Value("technology".to_string()),
            }),
        ],
    }),
};
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h2>
<h3 id="1-collection-configuration"><a class="header" href="#1-collection-configuration">1. Collection Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Optimize collection for your use case
let config = CollectionConfig {
    vectors_config: VectorsConfig::Single(VectorParams {
        size: 1536,
        distance: Distance::Cosine,
        on_disk: false, // Keep in memory for speed
    }),
    optimizers_config: OptimizersConfig {
        memmap_threshold: 20000,
        indexing_threshold: 20000,
        max_optimization_threads: 2,
    },
    wal_config: WalConfig {
        wal_capacity_mb: 32,
        wal_segments_ahead: 0,
    },
};
<span class="boring">}</span></code></pre></pre>
<h3 id="2-batch-processing"><a class="header" href="#2-batch-processing">2. Batch Processing</a></h3>
<ul>
<li>Use appropriate batch sizes (100-1000 points)</li>
<li>Process data in parallel when possible</li>
<li>Monitor memory usage for large datasets</li>
</ul>
<h3 id="3-indexing"><a class="header" href="#3-indexing">3. Indexing</a></h3>
<ul>
<li>Enable HNSW indexing for fast search</li>
<li>Configure index parameters based on data size</li>
<li>Use on-disk storage for large collections</li>
</ul>
<h2 id="error-handling-2"><a class="header" href="#error-handling-2">Error Handling</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match qdrant.search_points("collection", &amp;vector, 10).await {
    Ok(results) =&gt; {
        // Process search results
    },
    Err(Error::Qdrant(qdrant_error)) =&gt; {
        // Handle Qdrant-specific errors
        match qdrant_error {
            QdrantError::CollectionNotFound =&gt; {
                // Create collection or handle missing collection
            },
            QdrantError::InvalidVector =&gt; {
                // Handle vector dimension mismatch
            },
            _ =&gt; {
                // Handle other Qdrant errors
            }
        }
    },
    Err(Error::Network(network_error)) =&gt; {
        // Handle network connectivity issues
    },
    Err(e) =&gt; {
        // Handle other errors
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="1-collection-management"><a class="header" href="#1-collection-management">1. Collection Management</a></h3>
<ul>
<li>Use descriptive collection names</li>
<li>Set appropriate vector dimensions</li>
<li>Configure distance metrics based on your data</li>
</ul>
<h3 id="2-data-organization"><a class="header" href="#2-data-organization">2. Data Organization</a></h3>
<ul>
<li>Store relevant metadata in payload</li>
<li>Use consistent ID formats</li>
<li>Implement data versioning</li>
</ul>
<h3 id="3-search-optimization"><a class="header" href="#3-search-optimization">3. Search Optimization</a></h3>
<ul>
<li>Use appropriate score thresholds</li>
<li>Implement filtering for better results</li>
<li>Cache frequently accessed data</li>
</ul>
<h3 id="4-monitoring"><a class="header" href="#4-monitoring">4. Monitoring</a></h3>
<ul>
<li>Monitor collection sizes</li>
<li>Track search performance</li>
<li>Implement error logging</li>
</ul>
<h2 id="next-steps-5"><a class="header" href="#next-steps-5">Next Steps</a></h2>
<ul>
<li><a href="modules/qdrant/collections.html">Collections</a> - Deep dive into collection management</li>
<li><a href="modules/qdrant/vector-search.html">Vector Search</a> - Advanced search techniques</li>
<li><a href="modules/qdrant/../deployment/performance-tuning.html">Performance Tuning</a> - Optimize for scale</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="collections-1"><a class="header" href="#collections-1">Collections</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vector-search"><a class="header" href="#vector-search">Vector Search</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="overview-2"><a class="header" href="#overview-2">Overview</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chunking"><a class="header" href="#chunking">Chunking</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tokenization"><a class="header" href="#tokenization">Tokenization</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="overview-3"><a class="header" href="#overview-3">Overview</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="traces--spans"><a class="header" href="#traces--spans">Traces &amp; Spans</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="overview-4"><a class="header" href="#overview-4">Overview</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="base64"><a class="header" href="#base64">Base64</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="image-processing"><a class="header" href="#image-processing">Image Processing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="basic-chat-bot-1"><a class="header" href="#basic-chat-bot-1">Basic Chat Bot</a></h1>
<p>This example demonstrates how to build a simple chat bot using AI Utils that can maintain conversation context and provide helpful responses.</p>
<h2 id="overview-5"><a class="header" href="#overview-5">Overview</a></h2>
<pre><code class="language-mermaid">sequenceDiagram
    participant User
    participant Bot
    participant OpenAI
    
    User-&gt;&gt;Bot: Send message
    Bot-&gt;&gt;Bot: Add to conversation history
    Bot-&gt;&gt;OpenAI: Send conversation context
    OpenAI-&gt;&gt;Bot: Return response
    Bot-&gt;&gt;Bot: Add response to history
    Bot-&gt;&gt;User: Display response
</code></pre>
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<h3 id="1-basic-chat-bot"><a class="header" href="#1-basic-chat-bot">1. Basic Chat Bot</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::{
    openai::{OpenAIService, OpenAIMessage, OpenAIModel},
    error::Error,
};
use std::collections::VecDeque;

struct ChatBot {
    openai: OpenAIService,
    conversation_history: VecDeque&lt;OpenAIMessage&gt;,
    max_history: usize,
}

impl ChatBot {
    pub fn new() -&gt; Self {
        Self {
            openai: OpenAIService::new(),
            conversation_history: VecDeque::new(),
            max_history: 10, // Keep last 10 messages
        }
    }
    
    pub async fn chat(&amp;mut self, user_message: &amp;str) -&gt; Result&lt;String, Error&gt; {
        // Add user message to history
        self.add_message("user", user_message);
        
        // Create conversation for OpenAI
        let mut messages = vec![
            OpenAIMessage {
                role: "system".to_string(),
                content: "You are a helpful AI assistant. Provide clear, concise answers.".to_string(),
                name: None,
            },
        ];
        
        // Add conversation history
        messages.extend(self.conversation_history.iter().cloned());
        
        // Get response from OpenAI
        let response = self.openai.completion(messages, OpenAIModel::GPT35Turbo).await?;
        
        if let Some(choice) = response.choices.first() {
            let assistant_message = choice.message.content.clone();
            
            // Add assistant response to history
            self.add_message("assistant", &amp;assistant_message);
            
            Ok(assistant_message)
        } else {
            Err(Error::OpenAI("No response received".into()))
        }
    }
    
    fn add_message(&amp;mut self, role: &amp;str, content: &amp;str) {
        let message = OpenAIMessage {
            role: role.to_string(),
            content: content.to_string(),
            name: None,
        };
        
        self.conversation_history.push_back(message);
        
        // Maintain history size
        if self.conversation_history.len() &gt; self.max_history {
            self.conversation_history.pop_front();
        }
    }
    
    pub fn clear_history(&amp;mut self) {
        self.conversation_history.clear();
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-interactive-chat-loop"><a class="header" href="#2-interactive-chat-loop">2. Interactive Chat Loop</a></h3>
<pre><pre class="playground"><code class="language-rust">use std::io::{self, Write};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    dotenv::dotenv().ok();
    
    let mut bot = ChatBot::new();
    
    println!("ü§ñ AI Chat Bot initialized!");
    println!("Type 'quit' to exit, 'clear' to clear history\n");
    
    loop {
        print!("You: ");
        io::stdout().flush()?;
        
        let mut input = String::new();
        io::stdin().read_line(&amp;mut input)?;
        let input = input.trim();
        
        match input {
            "quit" | "exit" =&gt; {
                println!("Goodbye! üëã");
                break;
            },
            "clear" =&gt; {
                bot.clear_history();
                println!("Conversation history cleared!");
                continue;
            },
            "" =&gt; continue,
            _ =&gt; {
                match bot.chat(input).await {
                    Ok(response) =&gt; {
                        println!("Bot: {}", response);
                    },
                    Err(e) =&gt; {
                        println!("Error: {}", e);
                    }
                }
            }
        }
        
        println!(); // Add spacing
    }
    
    Ok(())
}</code></pre></pre>
<h3 id="3-enhanced-chat-bot-with-features"><a class="header" href="#3-enhanced-chat-bot-with-features">3. Enhanced Chat Bot with Features</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ai_utils::{
    openai::{OpenAIService, OpenAIMessage, OpenAIModel},
    error::Error,
};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ChatConfig {
    system_prompt: String,
    max_history: usize,
    model: OpenAIModel,
    temperature: f32,
}

impl Default for ChatConfig {
    fn default() -&gt; Self {
        Self {
            system_prompt: "You are a helpful AI assistant. Provide clear, concise answers.".to_string(),
            max_history: 10,
            model: OpenAIModel::GPT35Turbo,
            temperature: 0.7,
        }
    }
}

struct EnhancedChatBot {
    openai: OpenAIService,
    conversation_history: VecDeque&lt;OpenAIMessage&gt;,
    config: ChatConfig,
    user_preferences: HashMap&lt;String, String&gt;,
}

impl EnhancedChatBot {
    pub fn new(config: ChatConfig) -&gt; Self {
        Self {
            openai: OpenAIService::new(),
            conversation_history: VecDeque::new(),
            config,
            user_preferences: HashMap::new(),
        }
    }
    
    pub async fn chat(&amp;mut self, user_message: &amp;str) -&gt; Result&lt;String, Error&gt; {
        // Check for commands
        if let Some(command) = self.handle_command(user_message) {
            return Ok(command);
        }
        
        // Add user message to history
        self.add_message("user", user_message);
        
        // Build conversation with context
        let messages = self.build_conversation();
        
        // Get response from OpenAI
        let response = self.openai.completion(messages, self.config.model.clone()).await?;
        
        if let Some(choice) = response.choices.first() {
            let assistant_message = choice.message.content.clone();
            self.add_message("assistant", &amp;assistant_message);
            Ok(assistant_message)
        } else {
            Err(Error::OpenAI("No response received".into()))
        }
    }
    
    fn handle_command(&amp;mut self, message: &amp;str) -&gt; Option&lt;String&gt; {
        match message.to_lowercase().as_str() {
            "clear" =&gt; {
                self.conversation_history.clear();
                Some("Conversation history cleared!".to_string())
            },
            "help" =&gt; {
                Some(self.get_help_text())
            },
            "config" =&gt; {
                Some(format!("Current config: {:?}", self.config))
            },
            _ =&gt; None,
        }
    }
    
    fn build_conversation(&amp;self) -&gt; Vec&lt;OpenAIMessage&gt; {
        let mut messages = vec![
            OpenAIMessage {
                role: "system".to_string(),
                content: self.config.system_prompt.clone(),
                name: None,
            },
        ];
        
        messages.extend(self.conversation_history.iter().cloned());
        messages
    }
    
    fn get_help_text(&amp;self) -&gt; String {
        r#"
Available commands:
- clear: Clear conversation history
- help: Show this help message
- config: Show current configuration
- quit/exit: Exit the chat bot

Just type normally to chat with the AI!
        "#.trim().to_string()
    }
    
    fn add_message(&amp;mut self, role: &amp;str, content: &amp;str) {
        let message = OpenAIMessage {
            role: role.to_string(),
            content: content.to_string(),
            name: None,
        };
        
        self.conversation_history.push_back(message);
        
        if self.conversation_history.len() &gt; self.config.max_history {
            self.conversation_history.pop_front();
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="usage-examples"><a class="header" href="#usage-examples">Usage Examples</a></h2>
<h3 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut bot = ChatBot::new();

// Simple conversation
let response1 = bot.chat("Hello!").await?;
println!("Bot: {}", response1);

let response2 = bot.chat("What's the weather like?").await?;
println!("Bot: {}", response2);

// Bot remembers the conversation context
let response3 = bot.chat("What did I just ask you?").await?;
println!("Bot: {}", response3);
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-configuration"><a class="header" href="#custom-configuration">Custom Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = ChatConfig {
    system_prompt: "You are a technical support specialist. Help users with their technical issues.".to_string(),
    max_history: 20,
    model: OpenAIModel::GPT4,
    temperature: 0.3,
};

let mut bot = EnhancedChatBot::new(config);

let response = bot.chat("My computer won't turn on").await?;
println!("Support: {}", response);
<span class="boring">}</span></code></pre></pre>
<h2 id="key-features-2"><a class="header" href="#key-features-2">Key Features</a></h2>
<h3 id="1-conversation-memory"><a class="header" href="#1-conversation-memory">1. Conversation Memory</a></h3>
<ul>
<li>Maintains conversation history</li>
<li>Configurable history length</li>
<li>Context-aware responses</li>
</ul>
<h3 id="2-command-system"><a class="header" href="#2-command-system">2. Command System</a></h3>
<ul>
<li>Built-in commands (clear, help, config)</li>
<li>Extensible command handling</li>
<li>User-friendly interface</li>
</ul>
<h3 id="3-configuration"><a class="header" href="#3-configuration">3. Configuration</a></h3>
<ul>
<li>Customizable system prompts</li>
<li>Model selection</li>
<li>Temperature control</li>
<li>History management</li>
</ul>
<h3 id="4-error-handling"><a class="header" href="#4-error-handling">4. Error Handling</a></h3>
<ul>
<li>Graceful error handling</li>
<li>User-friendly error messages</li>
<li>Robust conversation flow</li>
</ul>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<h3 id="1-system-prompts"><a class="header" href="#1-system-prompts">1. System Prompts</a></h3>
<ul>
<li>Be specific about the bot's role</li>
<li>Include behavior guidelines</li>
<li>Set appropriate tone and style</li>
</ul>
<h3 id="2-history-management"><a class="header" href="#2-history-management">2. History Management</a></h3>
<ul>
<li>Keep history size reasonable (5-20 messages)</li>
<li>Clear history when starting new topics</li>
<li>Monitor token usage</li>
</ul>
<h3 id="3-error-handling-3"><a class="header" href="#3-error-handling-3">3. Error Handling</a></h3>
<ul>
<li>Always handle API errors gracefully</li>
<li>Provide helpful error messages</li>
<li>Implement retry logic for transient failures</li>
</ul>
<h3 id="4-user-experience"><a class="header" href="#4-user-experience">4. User Experience</a></h3>
<ul>
<li>Provide clear instructions</li>
<li>Include help commands</li>
<li>Make the interface intuitive</li>
</ul>
<h2 id="next-steps-6"><a class="header" href="#next-steps-6">Next Steps</a></h2>
<ul>
<li><a href="examples/document-qa.html">Document Q&amp;A</a> - Build a system that can answer questions about documents</li>
<li><a href="examples/multimodal-agent.html">Multimodal Agent</a> - Add image processing capabilities</li>
<li><a href="examples/../modules/openai/chat-completions.html">Advanced Features</a> - Explore advanced chat features</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="document-qa"><a class="header" href="#document-qa">Document Q&amp;A</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="image-analysis-1"><a class="header" href="#image-analysis-1">Image Analysis</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multimodal-agent"><a class="header" href="#multimodal-agent">Multimodal Agent</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="openai-service-2"><a class="header" href="#openai-service-2">OpenAI Service</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="qdrant-service-2"><a class="header" href="#qdrant-service-2">Qdrant Service</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="text-splitter-2"><a class="header" href="#text-splitter-2">Text Splitter</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="langfuse-service-1"><a class="header" href="#langfuse-service-1">Langfuse Service</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="common-types"><a class="header" href="#common-types">Common Types</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment Variables</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="production-setup"><a class="header" href="#production-setup">Production Setup</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="performance-tuning"><a class="header" href="#performance-tuning">Performance Tuning</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="development-setup"><a class="header" href="#development-setup">Development Setup</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-style"><a class="header" href="#code-style">Code Style</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing"><a class="header" href="#testing">Testing</a></h1>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
